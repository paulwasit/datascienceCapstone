
### parameters

```{r}
setwd('D:\\datascienceCapstone')
library(dplyr)

# sample size
lang <- "en_US"
sampleSize <- 10
minOccurences <- 10
```

### sample operations: sampling + sentences tokenization + unigrams

```{r}
source('./helpers/sampleUnigramsCreator.R')
createSampleUnigrams(lang, sampleSize, minOccurences)
rm(createSampleUnigrams,createSample,tokenizeSent,
   sent_token_annotator,tokenize,cleanUnigrams,filterUnigrams,createIndex)
```

### frequency tables

```{r}
G1_list <- readRDS(paste0("./data/",lang,".fullSample",sampleSize,".G1clean.Rds"))

source('./helpers/ngramFreqCreator.R')
nGramFreq <- getNgramFrequencies(G1_list,minOccurences)
rm(getNgramFrequencies,getFrequencies)

saveRDS(nGramFreq,paste0("./data/",lang,".fullSample",sampleSize,".nGramFreq.Rds"))
```

